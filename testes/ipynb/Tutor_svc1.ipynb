{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "''' features = atributos, nos exemplos scikit o padr\u00e3o \u00e9 dataset.data, por ex. iris.data\n",
      "    targets = classes, nos exemplos scikit o padr\u00e3o \u00e9 dataset.targets, ex. iris.target'''\n",
      "def cv_svm(exp):\n",
      "\n",
      "    # Baseado em: http://scikit-learn.org/stable/modules/cross_validation.html\n",
      "\n",
      "    print ('Obtendo os dados ja normalizados (minha lib classutil)')\n",
      "    features, targets = getdata(exp, normalize=True)\n",
      "\n",
      "    print ('Shape de features ', features.shape)\n",
      "\n",
      "    \n",
      "    # Aplicando o PCA (Opcao 1)\n",
      "    # features = ApplyPCA(features,targets, 2)\n",
      "    \n",
      "    '''\n",
      "    Esta fun\u00e7\u00e3o est\u00e1 na lib utilclass, o codigo \u00e9 apresentado abaixo:\n",
      "    \n",
      "    def ApplyPCA(X, y, n_components):\n",
      "        from sklearn.decomposition import RandomizedPCA\n",
      "        pca = RandomizedPCA(n_components=n_components).fit(X)\n",
      "        X_reduced = pca.transform(X,y)\n",
      "\n",
      "    return X_reduced\n",
      "    \n",
      "    '''\n",
      "\n",
      "    # Parti\u00e7\u00e3o de testes 20%    \n",
      "    test_part = 0.2\n",
      "    kernel = 'linear'\n",
      "\n",
      "    print('Parti\u00e7ionando os dado em testes e treino...')\n",
      "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(features, targets,\n",
      "                                                                         test_size=test_part, random_state=0)\n",
      "\n",
      "    '''\n",
      "    Para construir um hiperplano otimizado, SVM emprega um algoritmo iterativo, que \u00e9 utilizado para minimizar a\n",
      "    fun\u00e7\u00e3o de erro. SVM pode ser classificado em 4 grupos distintos, de acordo com o tipo da fun\u00e7\u00e3o de erro:\n",
      "\n",
      "    * Classification SVM Type 1 (also known as C-SVM classification)\n",
      "    * Classification SVM Type 2 (also known as nu-SVM classification)\n",
      "    * Regression SVM Type 1 (also known as epsilon-SVM regression)\n",
      "    * Regression SVM Type 2 (also known as nu-SVM regression)\n",
      "\n",
      "    https://www.statsoft.com/textbook/support-vector-machines\n",
      "\n",
      "    ------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "    No pacote scikit learn, sklearn.svm.SVC \u00e9 a fun\u00e7\u00e3o para 'C-Support Vector Classification', a implementa\u00e7\u00e3o \u00e9\n",
      "    baseada na libsvm, a complexidade no tempo \u00e9 mais do que quadratica, o que torna dificil para datasets com mais\n",
      "    de 10000 amostras\n",
      "\n",
      "    O suporte a multiclasses \u00e9 manipulado de acordo com o esquema um-vs-um.\n",
      "\n",
      "    http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
      "    '''\n",
      "\n",
      "\n",
      "    print (\"\",\"Aplicando o PCA (Opcao 2)\")\n",
      "    X_train, X_test =  apply_pca(2, X_train, X_test)\n",
      "    \n",
      "    '''\n",
      "    O codigo da funcao apply_pca \u00e9 apresentado abaixo:\n",
      "    def apply_pca(n_components, X_train, X_test):\n",
      "\n",
      "        # Computando o PCA\n",
      "        print (\"Extraindo os melhores %d componentes do set de treino => %d amostras\" % (n_components, X_train.shape[0]))\n",
      "        t0 = time.time()\n",
      "        pca = RandomizedPCA(n_components=n_components, whiten=True).fit(X_train)\n",
      "        print(\"realizado em %0.3fs\" % (time.time() - t0))\n",
      "\n",
      "        print (\"\",\"Projetando os dados em eigenfaces em bases ortogonais\")\n",
      "        t0 = time.time()\n",
      "        X_train_pca = pca.transform(X_train)\n",
      "        X_test_pca = pca.transform(X_test)\n",
      "        print(\"realizado em %0.3fs\" % (time.time() - t0))\n",
      "\n",
      "        return X_train_pca, X_test_pca\n",
      "    \n",
      "    '''\n",
      "\n",
      "\n",
      "    print ('Criando o classificador...')\n",
      "    clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
      "    scores_clf = clf.score(X_test, y_test)\n",
      "    ### print('Scores: ', clf.score(X_test, y_test))\n",
      "\n",
      "    print ('Estimando a precis\u00e3o de um kernel SVM em 5 k-folds...')\n",
      "    clf = svm.SVC(kernel=kernel, C=1)\n",
      "\n",
      "    print ('Computando o score (Acur\u00e1cia) ...')\n",
      "    scores_SVC = cross_validation.cross_val_score(clf, features, targets, cv=5)\n",
      "    print (scores_SVC)\n",
      "    \n",
      "\n",
      "    # Media e desvio padr\u00e3o\n",
      "    #  print(\"Accuracia: %0.2f (+/- %0.2f)\" % (scores_SVC.mean(), scores_SVC.std() * 2))\n",
      "\n",
      "    '''Por default, o score computado em cada intera\u00e7\u00e3o do CV \u00e9 atrav\u00e9s do metodo do\n",
      "     estimador. Isto pode ser alterado atrav\u00e9s da utiliza\u00e7\u00e3o do parametro scoring'''\n",
      "    score_f1 = cross_validation.cross_val_score(clf, features, targets, cv=5, scoring='f1')\n",
      "    print (score_f1)\n",
      "\n",
      "    '''\n",
      "    The scoring parameter: defining model evaluation rules\n",
      "    --------------------------------------------------------------\n",
      "    Scoring\t                Function\n",
      "    ---------------------------------------------------------------\n",
      "    Classification\n",
      "    \u2018accuracy\u2019          \tsklearn.metrics.accuracy_score\n",
      "    \u2018average_precision\u2019\t    sklearn.metrics.average_precision_score\n",
      "    \u2018f1\u2019\t                sklearn.metrics.f1_score\n",
      "    \u2018precision\u2019         \tsklearn.metrics.precision_score\n",
      "    \u2018recall\u2019\t            sklearn.metrics.recall_score\n",
      "    \u2018roc_auc\u2019           \tsklearn.metrics.roc_auc_score\n",
      "\n",
      "    Clustering\n",
      "    \u2018adjusted_rand_score\u2019\tsklearn.metrics.adjusted_rand_score\n",
      "\n",
      "    Regression\n",
      "    \u2018mean_squared_error\u2019\tsklearn.metrics.mean_squared_error\n",
      "    \u2018r2\u2019                \tsklearn.metrics.r2_score\n",
      "\n",
      "     http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
      "\n",
      "     Em an\u00e1lise estat\u00edstica de classifica\u00e7\u00e3o bin\u00e1ria, a pontua\u00e7\u00e3 F1 [F1 score (tamb\u00e9m chamado de F-score ou\n",
      "     F-meassure)] \u00e9 a  medida da acuracia. Esta medida considera a 'precisio' p e o 'recall' r do teste para computar\n",
      "     a pontua\u00e7\u00e3o (o score): p \u00e9 o n\u00famero de resultados corretos dividido pelo numero de todos os resultados e r \u00e9 o\n",
      "     n\u00famero de resultados corretos dividido pelo n\u00famero de resultados corretos que deveriam ser retornados.\n",
      "     F1 score tamb\u00e9m pode ser interpretado  como uma m\u00e9dia ponderada da precis\u00e3o e recall, onde uma pontua\u00e7\u00e3o F1\n",
      "     atinge o seu melhor valor em 1 e pior resultado em 0.\n",
      "\n",
      "     A F-measure tradicional ou pontua\u00e7\u00e3o balanceada (balanced F-score) \u00e9 a m\u00e9dia harm\u00f4nica entre a precis\u00e3o e o recall:\n",
      "\n",
      "        F1 = 2[(prexison.recall)/(precison+recall)]\n",
      "        fonte: http://en.wikipedia.org/wiki/F1_score\n",
      "\n",
      "    Quando o argumento (linha acima com o fragmento de codigo: score_f1 = ...) \u00e9 um inteiro,  cross_val_score usa\n",
      "    as strategias KFold ou StratifiedKFold por default (dependendo da presen\u00e7a ou da falta do array target (classes)\n",
      "\n",
      "    Tamb\u00e9m \u00e9 poss\u00edvel usar outra estrategia de cross validation passando diretamente um iterator de cross validation\n",
      "    em detrimento do default:\n",
      "    '''\n",
      "\n",
      "    n_samples = features.shape[0]\n",
      "    cv = cross_validation.ShuffleSplit(n_samples, n_iter=3, test_size=0.3, random_state=0)\n",
      "    cv_score_val = cross_validation.cross_val_score(clf, features, targets, cv=cv)\n",
      "\n",
      "    print (\"classification Report: \", time.strftime(\"%d/%m/%Y %I:%M:%S\"),end=\"\")\n",
      "    print (\"Descricao Experimento: \", exp['descricao'],end=\"\")\n",
      "    print (\"Classificador: \", exp['classificador'],end=\"\")\n",
      "    print (\"Kernel: \", kernel, end=\"\")\n",
      "    print (\"Teste Size: \", test_part, end=\"\")\n",
      "\n",
      "    print (\"\",\"**** Score do calssicador *****\")\n",
      "    print (\"svm.SVC, Kernel Linear, C=1: \", scores_clf)\n",
      "\n",
      "    print (\"\",\"**** Cross Validation Metrics *****\")\n",
      "    print (print(\"svm.SVC, Kernel Linear, C=1: \", scores_SVC))\n",
      "    print (\"\",\"***Media e Desvio a partir da do cross-validation***\")\n",
      "    print(\"Acuracia: %0.2f (+/- %0.2f)\" % (scores_SVC.mean(), scores_SVC.std() * 2))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}